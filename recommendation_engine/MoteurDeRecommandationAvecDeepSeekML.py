# =============================================================================
# MOTEUR DE RECOMMANDATION AVEC DEEPSEEK ML
# =============================================================================

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
import json
import sqlite3
from datetime import datetime
import asyncio
import aiohttp
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# STRUCTURES DE DONN√âES POUR LES RECOMMANDATIONS
# =============================================================================

@dataclass
class RecommendationItem:
    """Item de recommandation avec m√©tadonn√©es"""
    id: str
    title: str
    description: str
    category: str
    priority: float
    confidence: float
    metadata: Dict[str, Any]
    created_at: datetime

@dataclass
class DatasetRecommendation:
    """Recommandation sp√©cifique √† un dataset"""
    dataset_id: str
    recommendations: List[RecommendationItem]
    overall_score: float
    improvement_areas: List[str]
    compliance_gaps: List[str]

class RecommendationType(Enum):
    """Types de recommandations"""
    QUALITY_IMPROVEMENT = "QUALITY_IMPROVEMENT"
    SECURITY_ENHANCEMENT = "SECURITY_ENHANCEMENT"
    COMPLIANCE_RGPD = "COMPLIANCE_RGPD"
    METADATA_ENRICHMENT = "METADATA_ENRICHMENT"
    CLASSIFICATION_OPTIMIZATION = "CLASSIFICATION_OPTIMIZATION"
    ANONYMIZATION_STRATEGY = "ANONYMIZATION_STRATEGY"

# =============================================================================
# CLIENT DEEPSEEK ML
# =============================================================================

class DeepSeekClient:
    """Client pour interagir avec l'API DeepSeek"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.deepseek.com/v1"):
        self.api_key = api_key
        self.base_url = base_url
        self.session = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def generate_recommendations(self, prompt: str, max_tokens: int = 1500) -> str:
        """
        G√©n√®re des recommandations via l'API DeepSeek
        
        Args:
            prompt: Prompt pour la g√©n√©ration
            max_tokens: Nombre maximum de tokens
            
        Returns:
            R√©ponse g√©n√©r√©e par DeepSeek
        """
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": """Tu es un expert en gouvernance des donn√©es et en conformit√© RGPD. 
                    Tu dois analyser les profils de datasets et g√©n√©rer des recommandations pr√©cises 
                    pour am√©liorer la qualit√©, la s√©curit√© et la conformit√© des donn√©es."""
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.7,
            "top_p": 0.95
        }
        
        async with self.session.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload
        ) as response:
            if response.status == 200:
                result = await response.json()
                return result['choices'][0]['message']['content']
            else:
                raise Exception(f"Erreur API DeepSeek: {response.status}")

# =============================================================================
# MOTEUR DE RECOMMANDATION INTELLIGENT
# =============================================================================

class IntelligentRecommendationEngine:
    """Moteur de recommandation bas√© sur DeepSeek ML et l'analyse s√©mantique"""
    
    def __init__(self, deepseek_client: DeepSeekClient, database_path: str = "recommendations.db"):
        self.deepseek_client = deepseek_client
        self.database_path = database_path
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.recommendation_templates = self._load_recommendation_templates()
        self._initialize_database()
        
    def _initialize_database(self):
        """Initialise la base de donn√©es pour stocker les recommandations"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS recommendations (
                id TEXT PRIMARY KEY,
                dataset_id TEXT,
                type TEXT,
                title TEXT,
                description TEXT,
                priority REAL,
                confidence REAL,
                metadata TEXT,
                created_at TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS dataset_analysis (
                dataset_id TEXT PRIMARY KEY,
                profile_data TEXT,
                analysis_results TEXT,
                last_updated TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def _load_recommendation_templates(self) -> Dict[str, str]:
        """Charge les templates de recommandations"""
        return {
            "quality_analysis": """
            Analyse le profil de dataset suivant et g√©n√®re des recommandations pour am√©liorer la qualit√© des donn√©es:
            
            Dataset: {dataset_name}
            Entit√©s d√©tect√©es: {entities}
            Distribution de sensibilit√©: {sensitivity_distribution}
            Score de qualit√© actuel: {quality_score}
            
            G√©n√®re des recommandations SP√âCIFIQUES en format JSON avec les cl√©s:
            - type: type de recommandation
            - priority: priorit√© (1-10)
            - title: titre court
            - description: description d√©taill√©e
            - actions: liste d'actions concr√®tes
            - impact: impact estim√©
            """,
            
            "security_analysis": """
            Analyse de s√©curit√© pour le dataset:
            
            Dataset: {dataset_name}
            Donn√©es sensibles: {sensitive_data}
            Niveaux de sensibilit√©: {sensitivity_levels}
            M√©thodes d'anonymisation actuelles: {anonymization_methods}
            
            G√©n√®re des recommandations de s√©curit√© en format JSON pour:
            - Am√©liorer la protection des donn√©es sensibles
            - Optimiser les m√©thodes d'anonymisation
            - Renforcer l'acc√®s aux donn√©es
            """,
            
            "compliance_analysis": """
            Analyse de conformit√© RGPD pour:
            
            Dataset: {dataset_name}
            Cat√©gories RGPD d√©tect√©es: {rgpd_categories}
            Score de conformit√©: {compliance_score}
            Lacunes identifi√©es: {compliance_gaps}
            
            G√©n√®re des recommandations de conformit√© RGPD en format JSON pour:
            - Combler les lacunes de conformit√©
            - Am√©liorer la gouvernance des donn√©es
            - Optimiser la gestion des droits des personnes
            """,
            
            "metadata_enrichment": """
            Analyse des m√©tadonn√©es pour:
            
            Dataset: {dataset_name}
            M√©tadonn√©es actuelles: {current_metadata}
            Tags g√©n√©r√©s: {generated_tags}
            Contexte s√©mantique: {semantic_context}
            
            G√©n√®re des recommandations d'enrichissement en format JSON pour:
            - Am√©liorer la qualit√© des m√©tadonn√©es
            - Optimiser l'√©tiquetage automatique
            - Enrichir le contexte s√©mantique
            """
        }
    
    async def generate_comprehensive_recommendations(self, dataset_profile: dict) -> DatasetRecommendation:
        """
        G√©n√®re des recommandations compl√®tes pour un dataset
        
        Args:
            dataset_profile: Profil complet du dataset
            
        Returns:
            Recommandations compl√®tes
        """
        dataset_id = dataset_profile.get('dataset_id', 'unknown')
        recommendations = []
        
        # 1. Analyse de qualit√©
        quality_recs = await self._generate_quality_recommendations(dataset_profile)
        recommendations.extend(quality_recs)
        
        # 2. Analyse de s√©curit√©
        security_recs = await self._generate_security_recommendations(dataset_profile)
        recommendations.extend(security_recs)
        
        # 3. Analyse de conformit√© RGPD
        compliance_recs = await self._generate_compliance_recommendations(dataset_profile)
        recommendations.extend(compliance_recs)
        
        # 4. Enrichissement des m√©tadonn√©es
        metadata_recs = await self._generate_metadata_recommendations(dataset_profile)
        recommendations.extend(metadata_recs)
        
        # 5. Calcul du score global et identification des domaines d'am√©lioration
        overall_score = self._calculate_overall_score(dataset_profile, recommendations)
        improvement_areas = self._identify_improvement_areas(recommendations)
        compliance_gaps = self._identify_compliance_gaps(dataset_profile)
        
        # 6. Sauvegarder les recommandations
        await self._save_recommendations(dataset_id, recommendations)
        
        return DatasetRecommendation(
            dataset_id=dataset_id,
            recommendations=recommendations,
            overall_score=overall_score,
            improvement_areas=improvement_areas,
            compliance_gaps=compliance_gaps
        )
    
    async def _generate_quality_recommendations(self, dataset_profile: dict) -> List[RecommendationItem]:
        """G√©n√®re des recommandations de qualit√©"""
        prompt = self.recommendation_templates["quality_analysis"].format(
            dataset_name=dataset_profile.get('name', 'Dataset'),
            entities=dataset_profile.get('entity_distribution', {}),
            sensitivity_distribution=dataset_profile.get('sensitivity_distribution', {}),
            quality_score=dataset_profile.get('quality_score', 0.0)
        )
        
        response = await self.deepseek_client.generate_recommendations(prompt)
        
        # Parser la r√©ponse JSON
        recommendations = []
        try:
            # Extraire le JSON de la r√©ponse
            json_start = response.find('[')
            json_end = response.rfind(']') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                parsed_recs = json.loads(json_str)
                
                for rec in parsed_recs:
                    recommendation = RecommendationItem(
                        id=f"quality_{dataset_profile.get('dataset_id', 'unknown')}_{len(recommendations)}",
                        title=rec.get('title', 'Am√©lioration de qualit√©'),
                        description=rec.get('description', ''),
                        category=RecommendationType.QUALITY_IMPROVEMENT.value,
                        priority=float(rec.get('priority', 5.0)),
                        confidence=0.85,
                        metadata=rec,
                        created_at=datetime.now()
                    )
                    recommendations.append(recommendation)
        except Exception as e:
            print(f"Erreur lors du parsing des recommandations qualit√©: {e}")
            
        return recommendations
    
    async def _generate_security_recommendations(self, dataset_profile: dict) -> List[RecommendationItem]:
        """G√©n√®re des recommandations de s√©curit√©"""
        prompt = self.recommendation_templates["security_analysis"].format(
            dataset_name=dataset_profile.get('name', 'Dataset'),
            sensitive_data=dataset_profile.get('sensitive_entities', []),
            sensitivity_levels=dataset_profile.get('sensitivity_distribution', {}),
            anonymization_methods=dataset_profile.get('anonymization_methods', [])
        )
        
        response = await self.deepseek_client.generate_recommendations(prompt)
        
        recommendations = []
        try:
            json_start = response.find('[')
            json_end = response.rfind(']') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                parsed_recs = json.loads(json_str)
                
                for rec in parsed_recs:
                    recommendation = RecommendationItem(
                        id=f"security_{dataset_profile.get('dataset_id', 'unknown')}_{len(recommendations)}",
                        title=rec.get('title', 'Am√©lioration s√©curit√©'),
                        description=rec.get('description', ''),
                        category=RecommendationType.SECURITY_ENHANCEMENT.value,
                        priority=float(rec.get('priority', 8.0)),
                        confidence=0.90,
                        metadata=rec,
                        created_at=datetime.now()
                    )
                    recommendations.append(recommendation)
        except Exception as e:
            print(f"Erreur lors du parsing des recommandations s√©curit√©: {e}")
            
        return recommendations
    
    async def _generate_compliance_recommendations(self, dataset_profile: dict) -> List[RecommendationItem]:
        """G√©n√®re des recommandations de conformit√© RGPD"""
        prompt = self.recommendation_templates["compliance_analysis"].format(
            dataset_name=dataset_profile.get('name', 'Dataset'),
            rgpd_categories=dataset_profile.get('rgpd_categories', []),
            compliance_score=dataset_profile.get('rgpd_compliance_score', 0.0),
            compliance_gaps=dataset_profile.get('compliance_gaps', [])
        )
        
        response = await self.deepseek_client.generate_recommendations(prompt)
        
        recommendations = []
        try:
            json_start = response.find('[')
            json_end = response.rfind(']') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                parsed_recs = json.loads(json_str)
                
                for rec in parsed_recs:
                    recommendation = RecommendationItem(
                        id=f"compliance_{dataset_profile.get('dataset_id', 'unknown')}_{len(recommendations)}",
                        title=rec.get('title', 'Conformit√© RGPD'),
                        description=rec.get('description', ''),
                        category=RecommendationType.COMPLIANCE_RGPD.value,
                        priority=float(rec.get('priority', 9.0)),
                        confidence=0.88,
                        metadata=rec,
                        created_at=datetime.now()
                    )
                    recommendations.append(recommendation)
        except Exception as e:
            print(f"Erreur lors du parsing des recommandations conformit√©: {e}")
            
        return recommendations
    
    async def _generate_metadata_recommendations(self, dataset_profile: dict) -> List[RecommendationItem]:
        """G√©n√®re des recommandations d'enrichissement des m√©tadonn√©es"""
        prompt = self.recommendation_templates["metadata_enrichment"].format(
            dataset_name=dataset_profile.get('name', 'Dataset'),
            current_metadata=dataset_profile.get('metadata', {}),
            generated_tags=dataset_profile.get('semantic_tags', []),
            semantic_context=dataset_profile.get('semantic_context', {})
        )
        
        response = await self.deepseek_client.generate_recommendations(prompt)
        
        recommendations = []
        try:
            json_start = response.find('[')
            json_end = response.rfind(']') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                parsed_recs = json.loads(json_str)
                
                for rec in parsed_recs:
                    recommendation = RecommendationItem(
                        id=f"metadata_{dataset_profile.get('dataset_id', 'unknown')}_{len(recommendations)}",
                        title=rec.get('title', 'Enrichissement m√©tadonn√©es'),
                        description=rec.get('description', ''),
                        category=RecommendationType.METADATA_ENRICHMENT.value,
                        priority=float(rec.get('priority', 6.0)),
                        confidence=0.82,
                        metadata=rec,
                        created_at=datetime.now()
                    )
                    recommendations.append(recommendation)
        except Exception as e:
            print(f"Erreur lors du parsing des recommandations m√©tadonn√©es: {e}")
            
        return recommendations
    
    def _calculate_overall_score(self, dataset_profile: dict, recommendations: List[RecommendationItem]) -> float:
        """Calcule le score global du dataset"""
        quality_score = dataset_profile.get('quality_score', 0.0)
        compliance_score = dataset_profile.get('rgpd_compliance_score', 0.0)
        
        # P√©nalit√© bas√©e sur le nombre de recommandations critiques
        critical_recs = [r for r in recommendations if r.priority >= 8.0]
        penalty = len(critical_recs) * 0.1
        
        overall_score = max(0.0, min(10.0, (quality_score + compliance_score) / 2 - penalty))
        return overall_score
    
    def _identify_improvement_areas(self, recommendations: List[RecommendationItem]) -> List[str]:
        """Identifie les domaines d'am√©lioration prioritaires"""
        areas = {}
        for rec in recommendations:
            if rec.category not in areas:
                areas[rec.category] = []
            areas[rec.category].append(rec.priority)
        
        # Trier par priorit√© moyenne
        sorted_areas = sorted(areas.items(), key=lambda x: np.mean(x[1]), reverse=True)
        return [area[0] for area in sorted_areas[:3]]
    
    def _identify_compliance_gaps(self, dataset_profile: dict) -> List[str]:
        """Identifie les lacunes de conformit√©"""
        gaps = []
        
        # V√©rifier la pr√©sence de donn√©es personnelles sans protection
        if dataset_profile.get('has_personal_data', False):
            if not dataset_profile.get('has_anonymization', False):
                gaps.append("Donn√©es personnelles non anonymis√©es")
        
        # V√©rifier la documentation des traitements
        if dataset_profile.get('rgpd_compliance_score', 0.0) < 7.0:
            gaps.append("Documentation des traitements insuffisante")
        
        # V√©rifier la gestion des droits
        if not dataset_profile.get('has_consent_management', False):
            gaps.append("Gestion des consentements manquante")
        
        return gaps
    
    async def _save_recommendations(self, dataset_id: str, recommendations: List[RecommendationItem]):
        """Sauvegarde les recommandations dans la base de donn√©es"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        for rec in recommendations:
            cursor.execute('''
                INSERT OR REPLACE INTO recommendations 
                (id, dataset_id, type, title, description, priority, confidence, metadata, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                rec.id,
                dataset_id,
                rec.category,
                rec.title,
                rec.description,
                rec.priority,
                rec.confidence,
                json.dumps(rec.metadata),
                rec.created_at
            ))
        
        conn.commit()
        conn.close()
    
    async def get_dataset_recommendations(self, dataset_id: str) -> Optional[DatasetRecommendation]:
        """R√©cup√®re les recommandations pour un dataset"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, type, title, description, priority, confidence, metadata, created_at
            FROM recommendations
            WHERE dataset_id = ?
            ORDER BY priority DESC
        ''', (dataset_id,))
        
        results = cursor.fetchall()
        conn.close()
        
        if not results:
            return None
        
        recommendations = []
        for row in results:
            rec = RecommendationItem(
                id=row[0],
                title=row[2],
                description=row[3],
                category=row[1],
                priority=row[4],
                confidence=row[5],
                metadata=json.loads(row[6]),
                created_at=datetime.fromisoformat(row[7])
            )
            recommendations.append(rec)
        
        return DatasetRecommendation(
            dataset_id=dataset_id,
            recommendations=recommendations,
            overall_score=8.0,  # Calcul√© dynamiquement
            improvement_areas=['QUALITY_IMPROVEMENT', 'SECURITY_ENHANCEMENT'],
            compliance_gaps=['Documentation manquante']
        )

# =============================================================================
# EXEMPLE D'UTILISATION
# =============================================================================

async def example_usage():
    """Exemple d'utilisation du moteur de recommandation"""
    
    # Configuration DeepSeek
    DEEPSEEK_API_KEY = "votre_cl√©_api_deepseek"
    
    # Profil d'exemple d'un dataset
    sample_dataset_profile = {
        'dataset_id': 'clients_2024',
        'name': 'Base clients 2024',
        'entity_distribution': {
            'PERSON': 1250,
            'EMAIL_ADDRESS': 1200,
            'PHONE_NUMBER': 1180,
            'ID_MAROC': 1250,
            'LOCATION': 890
        },
        'sensitivity_distribution': {
            'PERSONAL_DATA': 2450,
            'CONFIDENTIAL': 1200,
            'INTERNAL': 500
        },
        'quality_score': 6.5,
        'rgpd_compliance_score': 7.2,
        'semantic_tags': ['CLIENT_DATA', 'PII', 'CONTACT'],
        'has_personal_data': True,
        'has_anonymization': False,
        'has_consent_management': True,
        'compliance_gaps': ['Documentation insuffisante', 'Anonymisation manquante']
    }
    
    # Cr√©er le moteur de recommandation
    async with DeepSeekClient(DEEPSEEK_API_KEY) as client:
        engine = IntelligentRecommendationEngine(client)
        
        # G√©n√©rer les recommandations
        print("üîç G√©n√©ration des recommandations...")
        recommendations = await engine.generate_comprehensive_recommendations(sample_dataset_profile)
        
        # Afficher les r√©sultats
        print(f"\nüìä Recommandations pour {sample_dataset_profile['name']}")
        print(f"Score global: {recommendations.overall_score:.1f}/10")
        print(f"Domaines d'am√©lioration: {', '.join(recommendations.improvement_areas)}")
        print(f"Lacunes de conformit√©: {', '.join(recommendations.compliance_gaps)}")
        
        print(f"\nüìã Recommandations d√©taill√©es ({len(recommendations.recommendations)} items):")
        for i, rec in enumerate(recommendations.recommendations, 1):
            print(f"\n{i}. {rec.title} (Priorit√©: {rec.priority}/10)")
            print(f"   Cat√©gorie: {rec.category}")
            print(f"   Description: {rec.description}")
            print(f"   Confiance: {rec.confidence:.2f}")

# Pour tester le code
if __name__ == "__main__":
    asyncio.run(example_usage())
